\begin{thebibliography}{99}
  \addcontentsline{toc}{chapter}{СПИСОК ЛИТЕРАТУРЫ}
  \bibitem{human-wer}
  Lippmann R. P. Speech recognition by machines and humans [Текст] // Speech communication. – 1997. – Т. 22. – №. 1. – С. 1-15.
  \bibitem{whisper}
  Radford A. et al. Robust speech recognition via large-scale weak supervision [Текст] // arXiv preprint arXiv:2212.04356. – 2022.
  \bibitem{state-of-gpt}
  Karpathy A. State of GPT [Электронный ресурс]. --- URL: \url{https://karpathy.ai/stateofgpt.pdf} (дата обр. 11.06.2023)
  \bibitem{transformer-paper}
  Vaswani A. et al. Attention is all you need [Текст] // Advances in neural information processing systems. – 2017. – Т. 30.
  \bibitem{llama-paper}
  Touvron H. et al. Llama: Open and efficient foundation language models [Текст] // arXiv preprint arXiv:2302.13971. – 2023.
  \bibitem{alpaca-docs}
  Документация Alpaca [Электронный ресурс]. --- URL: \url{https://crfm.stanford.edu/2023/03/13/alpaca.html} (дата обр. 06.06.2023)
  \bibitem{chatgpt-docs}
  Документация ChatGPT [Электронный ресурс]. --- URL: \url{https://openai.com/blog/chatgpt} (дата обр. 06.06.2023)
  \bibitem{MMLU-bench}
  Бенчмарк MMLU [Электронный ресурс]. --- URL: \url{https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu} (дата обр. 06.06.2023)
  \bibitem{flan-paper}
  Chung H. W. et al. Scaling instruction-finetuned language models [Текст] // arXiv preprint arXiv:2210.11416. – 2022.
  \bibitem{t5-paper}
  Raffel C. et al. Exploring the limits of transfer learning with a unified text-to-text transformer [Текст] // The Journal of Machine Learning Research. – 2020. – Т. 21. – №. 1. – С. 5485-5551.
\end{thebibliography}