\begin{thebibliography}{99}
  \addcontentsline{toc}{chapter}{СПИСОК ЛИТЕРАТУРЫ}
  \bibitem{human-wer}
  \textit{Lippmann R. P.} Speech recognition by machines and humans [Текст] // Speech communication. – 1997. – Т. 22. – №. 1. – С. 1-15.
  \bibitem{whisper}
  \textit{Radford A. et al.} Robust speech recognition via large-scale weak supervision [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/2212.04356.pdf} (дата обр. 11.06.2023)
  \bibitem{state-of-gpt}
  \textit{Karpathy A.} State of GPT [Электронный ресурс]. -- URL: \url{https://karpathy.ai/stateofgpt.pdf} (дата обр. 11.06.2023)
  \bibitem{transformer-paper}
  \textit{Vaswani A. et al.} Attention is all you need [Текст] // Advances in neural information processing systems. – 2017. – Т. 30.
  \bibitem{backprop-theory}
  \textit{Hecht-Nielsen R.} Theory of the backpropagation neural network [Текст] // Neural networks for perception. – Academic Press, 1992. – С. 65-93.
  \bibitem{optimizers-paper}
  \textit{Ruder S.} An overview of gradient descent optimization algorithms [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/1609.04747.pdf} (дата обр. 11.06.2023)
  \bibitem{adafactor-paper}
  \textit{Shazeer N., Stern M.} Adafactor: Adaptive learning rates with sublinear memory cost [Текст] // International Conference on Machine Learning. – PMLR, 2018. – С. 4596-4604.
  \bibitem{word2vec-paper}
  \textit{Mikolov T. et al.} Efficient estimation of word representations in vector space [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/1301.3781.pdf} (дата обр. 11.06.2023)
  \bibitem{bpe-paper}
  \textit{Sennrich R., Haddow B., Birch A.} Neural machine translation of rare words with subword units [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/1508.07909.pdf} (дата обр. 11.06.2023)
  \bibitem{gpt-paper}
  \textit{Radford A. et al.} Improving language understanding by generative pre-training [Электронный ресурс].  -- URL: \url{https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf} (дата обр. 11.06.2023)
  \bibitem{t5-paper}
  \textit{Raffel C. et al.} Exploring the limits of transfer learning with a unified text-to-text transformer [Текст] // The Journal of Machine Learning Research. – 2020. – Т. 21. – №. 1. – С. 5485-5551.
  \bibitem{bert-paper}
  \textit{Devlin J. et al.} Bert: Pre-training of deep bidirectional transformers for language understanding [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/1810.04805.pdf} (дата обр. 11.06.2023)
  \bibitem{chatgpt-docs}
  Документация ChatGPT [Электронный ресурс]. -- URL: \url{https://openai.com/blog/chatgpt} (дата обр. 06.06.2023)
  \bibitem{llama-paper}
  \textit{Touvron H. et al.} Llama: Open and efficient foundation language models [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/2302.13971.pdf}
  \bibitem{alpaca-docs}
  Документация Alpaca [Электронный ресурс]. -- URL: \url{https://crfm.stanford.edu/2023/03/13/alpaca.html} (дата обр. 06.06.2023)
  \bibitem{flan-paper}
  \textit{Chung H. W. et al.} Scaling instruction-finetuned language models [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/2210.11416.pdf} (дата обр. 11.06.2023)
  \bibitem{sentencepiece-paper}
  \textit{Kudo T., Richardson J.} Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing [Электронный ресурс]. -- URL: \url{https://arxiv.org/pdf/1808.06226.pdf} (дата обр. 11.06.2023)
  \bibitem{python-lang-site}
  Официальный сайт языка программирования Python [Электронный ресурс]. -- URL: \url{https://www.python.org/} (дата обр. 16.06.2023)
  \bibitem{cpp-docs}
  Документация языка C++ [Электронный ресурс]. -- URL: \url{https://en.cppreference.com/w/} (дата обр. 16.06.2023)
  \bibitem{cuda-docs}
  Документация CUDA [Электронный ресурс]. -- URL: \url{https://docs.nvidia.com/cuda/} (дата обр. 16.06.2023)
  \bibitem{gradio-docs}
  Документация фреймворка Gradio [Электронный ресурс]. -- URL: \url{https://www.gradio.app/docs/} (дата обр. 16.06.2023)
  \bibitem{tqdm-docs}
  Документация библиотеки tqdm [Электронный ресурс]. -- URL: \url{https://tqdm.github.io/} (дата обр. 16.06.2023)
  \bibitem{hf-datasets-docs}
  Документация библиотеки Datasets [Электронный ресурс]. -- URL: \url{https://huggingface.co/docs/datasets/index} (дата обр. 16.06.2023)
  \bibitem{transformers-docs}
  Документация библиотеки Transformers [Электронный ресурс]. -- URL: \url{https://huggingface.co/docs/transformers/index} (дата обр. 16.06.2023)
  \bibitem{pandas-docs}
  Документация библиотеки pandas [Электронный ресурс]. -- URL: \url{https://pandas.pydata.org/docs/} (дата обр. 16.06.2023)
  \bibitem{peft-docs}
  Документация библиотеки PEFT [Электронный ресурс]. -- URL: \url{https://huggingface.co/docs/peft/index} (дата обр. 16.06.2023)
  \bibitem{wandb-docs}
  Документация библиотеки Weights \& Biases [Электронный ресурс]. -- URL: \url{https://docs.wandb.ai/} (дата обр. 16.06.2023)
  \bibitem{weidu-repo}
  Репозиторий проекта WeiDU [Электронный ресурс]. -- URL: \url{https://github.com/WeiDUorg/weidu} (дата обр. 16.06.2023)
  \bibitem{MMLU-bench}
  Соревнование на наборе данных MMLU [Электронный ресурс]. -- URL: \url{https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu} (дата обр. 06.06.2023)
  \bibitem{mauve-paper}
  \textit{Pillutla K. et al.} Mauve: Measuring the gap between neural text and human text using divergence frontiers [Текст] // Advances in Neural Information Processing Systems. – 2021. – Т. 34. – С. 4816-4828.
  \bibitem{flash-attn-paper}
  \textit{Dao T. et al.} Flashattention: Fast and memory-efficient exact attention with io-awareness [Текст] // Advances in Neural Information Processing Systems. – 2022. – Т. 35. – С. 16344-16359.
  \bibitem{pt-docs}
  Документация фреймворка PyTorch [Электронный ресурс]. -- URL: \url{https://pytorch.org/docs/stable/index.html} (дата обр. 16.06.2023)
  \bibitem{nti-paper}
  \textit{Бурлаков В. С., Ишутин М. А., Пятанин А. А.} Диалоговая система для разработчиков видеоигр [Текст]// Наука. Технологии. Инновации : сб. науч. тр. : в 11 ч., Новосибирск, 05-08 дек. 2022 г. Ч. 2 -- Изд-во НГТУ, 2022. -- C. 101-104.
\end{thebibliography}